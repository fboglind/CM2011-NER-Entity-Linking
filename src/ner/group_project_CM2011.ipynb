{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "517caaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tqdm as notebook_tqdm\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from seqeval.metrics import (precision_score,\n",
    "                             recall_score,\n",
    "                             f1_score,\n",
    "                             classification_report)\n",
    "\n",
    "from datasets import (load_dataset,\n",
    "                      DatasetDict, \n",
    "                      Features, \n",
    "                      Sequence, \n",
    "                      ClassLabel, \n",
    "                      Value, \n",
    "                      interleave_datasets, \n",
    "                      get_dataset_config_names, \n",
    "                      load_dataset, \n",
    "                      load_from_disk\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "from utility_functions import (split_sources,\n",
    "                            #    whitespace_tokens_with_spans,\n",
    "                            #    spans_to_bio_labels,\n",
    "                               build_bio_label_list_from_sources, \n",
    "                            #    make_to_features, \n",
    "                            #    process_all,\n",
    "                            #    normalize_types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571229ac",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1c75b2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available configurations:\n",
      "- 1177\n",
      "- lt\n",
      "- wiki\n"
     ]
    }
   ],
   "source": [
    "# We list all available configurations of the dataset:\n",
    "# configs = get_dataset_config_names(\"bigbio/swedish_medical_ner\")\n",
    "configs = get_dataset_config_names(\"community-datasets/swedish_medical_ner\")\n",
    "print(\"Available configurations:\")\n",
    "for config in configs:\n",
    "    print(f\"- {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ba4a7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load from: data/swedish_medical_ner_1177\n",
      "Loading configuration: 1177 from disk\n",
      "{'entities': Sequence(feature={'end': Value(dtype='int32', id=None),\n",
      "                               'start': Value(dtype='int32', id=None),\n",
      "                               'text': Value(dtype='string', id=None),\n",
      "                               'type': ClassLabel(names=['Disorder and Finding',\n",
      "                                                         'Pharmaceutical Drug',\n",
      "                                                         'Body Structure'],\n",
      "                                                  id=None)},\n",
      "                      length=-1,\n",
      "                      id=None),\n",
      " 'sentence': Value(dtype='string', id=None),\n",
      " 'sid': Value(dtype='string', id=None)}\n",
      "Attempting to load from: data/swedish_medical_ner_lt\n",
      "Loading configuration: lt from disk\n",
      "{'entities': Sequence(feature={'end': Value(dtype='int32', id=None),\n",
      "                               'start': Value(dtype='int32', id=None),\n",
      "                               'text': Value(dtype='string', id=None),\n",
      "                               'type': ClassLabel(names=['Disorder and Finding',\n",
      "                                                         'Pharmaceutical Drug',\n",
      "                                                         'Body Structure'],\n",
      "                                                  id=None)},\n",
      "                      length=-1,\n",
      "                      id=None),\n",
      " 'sentence': Value(dtype='string', id=None),\n",
      " 'sid': Value(dtype='string', id=None)}\n",
      "Attempting to load from: data/swedish_medical_ner_wiki\n",
      "Loading configuration: wiki from disk\n",
      "{'entities': Sequence(feature={'end': Value(dtype='int32', id=None),\n",
      "                               'start': Value(dtype='int32', id=None),\n",
      "                               'text': Value(dtype='string', id=None),\n",
      "                               'type': ClassLabel(names=['Disorder and Finding',\n",
      "                                                         'Pharmaceutical Drug',\n",
      "                                                         'Body Structure'],\n",
      "                                                  id=None)},\n",
      "                      length=-1,\n",
      "                      id=None),\n",
      " 'sentence': Value(dtype='string', id=None),\n",
      " 'sid': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "# The dataset is loaded with all the chosen configurations\n",
    "\n",
    "kb_datasets =[]\n",
    "for config in configs:\n",
    "    print(f\"Attempting to load from: data/swedish_medical_ner_{config}\")\n",
    "    if os.path.isdir(f\"data/swedish_medical_ner_{config}/train\"):\n",
    "        print(f\"Loading configuration: {config} from disk\")\n",
    "        try:\n",
    "            ds = load_from_disk(f\"data/swedish_medical_ner_{config}\")\n",
    "            ds.config_name = config  # Attach config name as an attribute for later access.\n",
    "            kb_datasets.append(ds)\n",
    "            pprint(ds[\"train\"].features) #Display schema  \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load dataset from disk for config {config}: {e}\")\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(f\"Loading configuration: {config} from the huggingface hub\")\n",
    "        ds = load_dataset(\"community-datasets/swedish_medical_ner\", config)\n",
    "        ds.config_name = config  # Attach config name as an attribute for later access.\n",
    "        print(f\"- {ds.config_name}\")\n",
    "        pprint(ds[\"train\"].features) #Display schema\n",
    "        kb_datasets.append(ds)\n",
    "        #Saving to disk\n",
    "        ds.save_to_disk(f\"data/swedish_medical_ner_{ds.config_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81909adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Configuration 1: 1177\n",
      "Rows: 927\n",
      "Columns: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1177_0</td>\n",
       "      <td>Memantin ( Ebixa ) ger sällan några biverkningar.</td>\n",
       "      <td>{'start': [9], 'end': [18], 'text': ['Ebixa'], 'type': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1177_1</td>\n",
       "      <td>Det är också lättare att dosera [ flytande medicin ] än att dela på tabletter.</td>\n",
       "      <td>{'start': [32], 'end': [52], 'text': ['flytande medicin'], 'type': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1177_2</td>\n",
       "      <td>( Förstoppning ) är ett vanligt problem hos äldre.</td>\n",
       "      <td>{'start': [0], 'end': [16], 'text': ['Förstoppning'], 'type': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1177_3</td>\n",
       "      <td>[ Medicinen ] kan också göra att man blöder lättare eftersom den påverkar { blodets } förmåga att levra sig.</td>\n",
       "      <td>{'start': [0, 74], 'end': [13, 85], 'text': ['Medicinen', 'blodets'], 'type': [1, 2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1177_4</td>\n",
       "      <td>Barn har större möjligheter att samarbeta om de i förväg får veta vad som ska hända.</td>\n",
       "      <td>{'start': [], 'end': [], 'text': [], 'type': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1177_5</td>\n",
       "      <td>Eftersom de påverkar hela kroppen mer än övriga mediciner bör man bara ta dem när olika kombinationer av receptfria mediciner inte hjälper.</td>\n",
       "      <td>{'start': [], 'end': [], 'text': [], 'type': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1177_6</td>\n",
       "      <td>För att få ett skydd mot ( hepatit B ) behövs tre doser vaccin.</td>\n",
       "      <td>{'start': [25], 'end': [38], 'text': ['hepatit B'], 'type': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1177_7</td>\n",
       "      <td>Effekten av naproxen sitter i längre och varar cirka 12 timmar jämfört med cirka 6 timmar för ibuprofen.</td>\n",
       "      <td>{'start': [], 'end': [], 'text': [], 'type': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1177_8</td>\n",
       "      <td>[ Cox-hämmare ] finns även som gel och sprej.</td>\n",
       "      <td>{'start': [0], 'end': [15], 'text': ['Cox-hämmare'], 'type': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1177_9</td>\n",
       "      <td>Det är bra om ett litet barn är mätt och utsövt, eftersom de flesta påfrestningar då känns mindre.</td>\n",
       "      <td>{'start': [], 'end': [], 'text': [], 'type': []}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sid  \\\n",
       "0  1177_0   \n",
       "1  1177_1   \n",
       "2  1177_2   \n",
       "3  1177_3   \n",
       "4  1177_4   \n",
       "5  1177_5   \n",
       "6  1177_6   \n",
       "7  1177_7   \n",
       "8  1177_8   \n",
       "9  1177_9   \n",
       "\n",
       "                                                                                                                                      sentence  \\\n",
       "0                                                                                            Memantin ( Ebixa ) ger sällan några biverkningar.   \n",
       "1                                                               Det är också lättare att dosera [ flytande medicin ] än att dela på tabletter.   \n",
       "2                                                                                           ( Förstoppning ) är ett vanligt problem hos äldre.   \n",
       "3                                 [ Medicinen ] kan också göra att man blöder lättare eftersom den påverkar { blodets } förmåga att levra sig.   \n",
       "4                                                         Barn har större möjligheter att samarbeta om de i förväg får veta vad som ska hända.   \n",
       "5  Eftersom de påverkar hela kroppen mer än övriga mediciner bör man bara ta dem när olika kombinationer av receptfria mediciner inte hjälper.   \n",
       "6                                                                              För att få ett skydd mot ( hepatit B ) behövs tre doser vaccin.   \n",
       "7                                     Effekten av naproxen sitter i längre och varar cirka 12 timmar jämfört med cirka 6 timmar för ibuprofen.   \n",
       "8                                                                                                [ Cox-hämmare ] finns även som gel och sprej.   \n",
       "9                                           Det är bra om ett litet barn är mätt och utsövt, eftersom de flesta påfrestningar då känns mindre.   \n",
       "\n",
       "                                                                                entities  \n",
       "0                            {'start': [9], 'end': [18], 'text': ['Ebixa'], 'type': [0]}  \n",
       "1                {'start': [32], 'end': [52], 'text': ['flytande medicin'], 'type': [1]}  \n",
       "2                     {'start': [0], 'end': [16], 'text': ['Förstoppning'], 'type': [0]}  \n",
       "3  {'start': [0, 74], 'end': [13, 85], 'text': ['Medicinen', 'blodets'], 'type': [1, 2]}  \n",
       "4                                       {'start': [], 'end': [], 'text': [], 'type': []}  \n",
       "5                                       {'start': [], 'end': [], 'text': [], 'type': []}  \n",
       "6                       {'start': [25], 'end': [38], 'text': ['hepatit B'], 'type': [0]}  \n",
       "7                                       {'start': [], 'end': [], 'text': [], 'type': []}  \n",
       "8                      {'start': [0], 'end': [15], 'text': ['Cox-hämmare'], 'type': [1]}  \n",
       "9                                       {'start': [], 'end': [], 'text': [], 'type': []}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Configuration 2: lt\n",
      "Rows: 745753\n",
      "Columns: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lt_0</td>\n",
       "      <td>, (hjärtinfarkt) och (syndrom) som vi nu år 1999 inte ens vet na</td>\n",
       "      <td>{'start': [2, 21], 'end': [16, 30], 'text': ['hjärtinfarkt', 'syndrom'], 'type': [0, 0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lt_1</td>\n",
       "      <td>tinernas goda effekt på morbiditeten är välkänd, och data hi</td>\n",
       "      <td>{'start': [], 'end': [], 'text': [], 'type': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lt_2</td>\n",
       "      <td>[sukralfat], [lakrits] och vismut) som kunde utgöra ett skydd öv</td>\n",
       "      <td>{'start': [0, 13], 'end': [11, 22], 'text': ['sukralfat', 'lakrits'], 'type': [1, 1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lt_3</td>\n",
       "      <td>och tveksamhet {vad} gäller operationsindikationen kan man ha</td>\n",
       "      <td>{'start': [16], 'end': [21], 'text': ['vad'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lt_4</td>\n",
       "      <td>1989 blev en anmälningspliktig (sjukdom) enligt Smittskyddsla</td>\n",
       "      <td>{'start': [32], 'end': [41], 'text': ['sjukdom'], 'type': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lt_5</td>\n",
       "      <td>kombinerat med remodellering av (hjärtat). Detta säkras genom</td>\n",
       "      <td>{'start': [32], 'end': [41], 'text': ['hjärtat'], 'type': [0]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lt_6</td>\n",
       "      <td>olyckshändelse radikalt förändrat deras liv. {Sigmoideum} är</td>\n",
       "      <td>{'start': [46], 'end': [58], 'text': ['Sigmoideum'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lt_7</td>\n",
       "      <td>ra att hon samtidigt ordinerade [Cyklokapron] i en mängd av 5</td>\n",
       "      <td>{'start': [32], 'end': [45], 'text': ['Cyklokapron'], 'type': [1]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lt_8</td>\n",
       "      <td>till vara erfarenheterna och föra ut kunskapen till sjukvård</td>\n",
       "      <td>{'start': [], 'end': [], 'text': [], 'type': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lt_9</td>\n",
       "      <td>es kring behandling med betablockad vid (kronisk hjärtsvikt).</td>\n",
       "      <td>{'start': [40], 'end': [60], 'text': ['kronisk hjärtsvikt'], 'type': [0]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sid                                                          sentence  \\\n",
       "0  lt_0  , (hjärtinfarkt) och (syndrom) som vi nu år 1999 inte ens vet na   \n",
       "1  lt_1      tinernas goda effekt på morbiditeten är välkänd, och data hi   \n",
       "2  lt_2  [sukralfat], [lakrits] och vismut) som kunde utgöra ett skydd öv   \n",
       "3  lt_3     och tveksamhet {vad} gäller operationsindikationen kan man ha   \n",
       "4  lt_4     1989 blev en anmälningspliktig (sjukdom) enligt Smittskyddsla   \n",
       "5  lt_5    kombinerat med remodellering av (hjärtat). Detta säkras genom    \n",
       "6  lt_6     olyckshändelse radikalt förändrat deras liv. {Sigmoideum} är    \n",
       "7  lt_7    ra att hon samtidigt ordinerade [Cyklokapron] i en mängd av 5    \n",
       "8  lt_8      till vara erfarenheterna och föra ut kunskapen till sjukvård   \n",
       "9  lt_9    es kring behandling med betablockad vid (kronisk hjärtsvikt).    \n",
       "\n",
       "                                                                                   entities  \n",
       "0  {'start': [2, 21], 'end': [16, 30], 'text': ['hjärtinfarkt', 'syndrom'], 'type': [0, 0]}  \n",
       "1                                          {'start': [], 'end': [], 'text': [], 'type': []}  \n",
       "2     {'start': [0, 13], 'end': [11, 22], 'text': ['sukralfat', 'lakrits'], 'type': [1, 1]}  \n",
       "3                                {'start': [16], 'end': [21], 'text': ['vad'], 'type': [2]}  \n",
       "4                            {'start': [32], 'end': [41], 'text': ['sjukdom'], 'type': [0]}  \n",
       "5                            {'start': [32], 'end': [41], 'text': ['hjärtat'], 'type': [0]}  \n",
       "6                         {'start': [46], 'end': [58], 'text': ['Sigmoideum'], 'type': [2]}  \n",
       "7                        {'start': [32], 'end': [45], 'text': ['Cyklokapron'], 'type': [1]}  \n",
       "8                                          {'start': [], 'end': [], 'text': [], 'type': []}  \n",
       "9                 {'start': [40], 'end': [60], 'text': ['kronisk hjärtsvikt'], 'type': [0]}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Configuration 3: wiki\n",
      "Rows: 48720\n",
      "Columns: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wiki_0</td>\n",
       "      <td>{kropp} beskrivs i till exempel människokroppen, anatomi och f</td>\n",
       "      <td>{'start': [0], 'end': [7], 'text': ['kropp'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wiki_1</td>\n",
       "      <td>sju miljoner år gammalt hominint {kranium}, klassificerad som</td>\n",
       "      <td>{'start': [33], 'end': [42], 'text': ['kranium'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wiki_2</td>\n",
       "      <td>autosomer och ett par könskromosomer. Varje {kromosom} består</td>\n",
       "      <td>{'start': [45], 'end': [55], 'text': ['kromosom'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wiki_3</td>\n",
       "      <td>{kromosom} består av en DNA-molekyl och {protein}. En DNA-molek</td>\n",
       "      <td>{'start': [1], 'end': [50], 'text': ['kromosom} består av en DNA-molekyl och {protein'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wiki_4</td>\n",
       "      <td>tikel:Människans {skelett} Människans skelett är det skelett s</td>\n",
       "      <td>{'start': [17], 'end': [26], 'text': ['skelett'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wiki_5</td>\n",
       "      <td>os människor. En vuxen människas {skelett} består av 206 till</td>\n",
       "      <td>{'start': [33], 'end': [42], 'text': ['skelett'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wiki_6</td>\n",
       "      <td>{lett} består av 206 till 220 {ben}, beroende på hur man räknar.</td>\n",
       "      <td>{'start': [0], 'end': [35], 'text': ['lett} består av 206 till 220 {ben'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>wiki_7</td>\n",
       "      <td>v kroppsvikten.Ett nyfött barn har ca 300 {ben} i kroppen vilk</td>\n",
       "      <td>{'start': [42], 'end': [47], 'text': ['ben'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wiki_8</td>\n",
       "      <td>kollektivet i mindre bitar såsom länder &gt; städer &gt; orter {Hud}</td>\n",
       "      <td>{'start': [57], 'end': [62], 'text': ['Hud'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wiki_9</td>\n",
       "      <td>sdjur. {Huden} utgör ett mekaniskt skydd mot omvärlden och bid</td>\n",
       "      <td>{'start': [7], 'end': [14], 'text': ['Huden'], 'type': [2]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sid                                                          sentence  \\\n",
       "0  wiki_0    {kropp} beskrivs i till exempel människokroppen, anatomi och f   \n",
       "1  wiki_1    sju miljoner år gammalt hominint {kranium}, klassificerad som    \n",
       "2  wiki_2     autosomer och ett par könskromosomer. Varje {kromosom} består   \n",
       "3  wiki_3   {kromosom} består av en DNA-molekyl och {protein}. En DNA-molek   \n",
       "4  wiki_4    tikel:Människans {skelett} Människans skelett är det skelett s   \n",
       "5  wiki_5    os människor. En vuxen människas {skelett} består av 206 till    \n",
       "6  wiki_6  {lett} består av 206 till 220 {ben}, beroende på hur man räknar.   \n",
       "7  wiki_7    v kroppsvikten.Ett nyfött barn har ca 300 {ben} i kroppen vilk   \n",
       "8  wiki_8    kollektivet i mindre bitar såsom länder > städer > orter {Hud}   \n",
       "9  wiki_9    sdjur. {Huden} utgör ett mekaniskt skydd mot omvärlden och bid   \n",
       "\n",
       "                                                                                                entities  \n",
       "0                                             {'start': [0], 'end': [7], 'text': ['kropp'], 'type': [2]}  \n",
       "1                                         {'start': [33], 'end': [42], 'text': ['kranium'], 'type': [2]}  \n",
       "2                                        {'start': [45], 'end': [55], 'text': ['kromosom'], 'type': [2]}  \n",
       "3  {'start': [1], 'end': [50], 'text': ['kromosom} består av en DNA-molekyl och {protein'], 'type': [2]}  \n",
       "4                                         {'start': [17], 'end': [26], 'text': ['skelett'], 'type': [2]}  \n",
       "5                                         {'start': [33], 'end': [42], 'text': ['skelett'], 'type': [2]}  \n",
       "6                {'start': [0], 'end': [35], 'text': ['lett} består av 206 till 220 {ben'], 'type': [2]}  \n",
       "7                                             {'start': [42], 'end': [47], 'text': ['ben'], 'type': [2]}  \n",
       "8                                             {'start': [57], 'end': [62], 'text': ['Hud'], 'type': [2]}  \n",
       "9                                            {'start': [7], 'end': [14], 'text': ['Huden'], 'type': [2]}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The three configurations are explored\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "for i, dataset in enumerate(kb_datasets):\n",
    "    print(f\"### Configuration {i + 1}: {dataset.config_name}\")\n",
    "    print(f\"Rows: {dataset['train'].num_rows}\")  # Shows splits and number of examples\n",
    "    print(f\"Columns: {len(dataset['train'].features)}\")  # Number of columns/features\n",
    "\n",
    "    # Convert a slice of the dataset to a pandas dataframe and display it\n",
    "    example = dataset[\"train\"].select(range(10)).to_pandas()\n",
    "    display(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d6b6cb",
   "metadata": {},
   "source": [
    "We have three configurations (subsets) with varying size\n",
    "\n",
    "The data of interest are:\n",
    "* Passage text (a full sentence (1177) or part of a sentence (wiki, lt)).\n",
    "* The Named Entities (bracketed using: (), [] {}),\n",
    "* their starting and ending positions: start, end,\n",
    "* and their types (0,1 and 2).\n",
    "\n",
    "The types refer to the the different types of named entities (we may also call them labels or classes):\n",
    "* 'Pharmaceutical Drug': 0\n",
    "* 'Disorder and Finding': 1\n",
    "* 'Body Structure': 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e1d33d",
   "metadata": {},
   "source": [
    "## The task: NER\n",
    "\n",
    "\n",
    "The task of Named entity Recognition (NER) is one of sequence labeling, where each token in a sentence must be tagged.\n",
    "\n",
    "The following sentence contains two Named Entities of different types (1,2):\n",
    "\n",
    "`[ Medicinen ] kan också göra att man blöder lättare eftersom den påverkar { blodets } förmåga att levra sig.\t{'start': [0, 74], 'end': [13, 85], 'text': ['Medicinen', 'blodets'], 'type': [1, 2]}`\n",
    "\n",
    "As we can see, the raw data gives the named entities as *spans* with start/end positions.\n",
    "The logical next step is to convert the spans to *per-token labels*, i e to associate each token within a sentence with it's corresponding type label.\n",
    "\n",
    "First however, we split the configurations into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5207da2b",
   "metadata": {},
   "source": [
    "### 1) Split each config into train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "effa739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1177': DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sid', 'sentence', 'entities', 'source'],\n",
      "        num_rows: 880\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sid', 'sentence', 'entities', 'source'],\n",
      "        num_rows: 47\n",
      "    })\n",
      "}), 'lt': DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sid', 'sentence', 'entities', 'source'],\n",
      "        num_rows: 708465\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sid', 'sentence', 'entities', 'source'],\n",
      "        num_rows: 37288\n",
      "    })\n",
      "}), 'wiki': DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sid', 'sentence', 'entities', 'source'],\n",
      "        num_rows: 46284\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sid', 'sentence', 'entities', 'source'],\n",
      "        num_rows: 2436\n",
      "    })\n",
      "})}\n"
     ]
    }
   ],
   "source": [
    "per_source_raw= split_sources(kb_datasets, val_fraction=0.05, seed=42)\n",
    "print(per_source_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32681b3",
   "metadata": {},
   "source": [
    "### 2) Convert entities to list-of-dicts format.\n",
    "\n",
    "We keep `type` as `int` `ClassLabel`in order to keep the downstream code cleaner, and to simplify iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60377ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_of_lists_to_list_of_dicts(entities_dict):\n",
    "    \"\"\"Convert a dictionary of lists to a list of dictionaries.\"\"\"\n",
    "    return [\n",
    "        {\"start\": s, \"end\": e, \"text\": txt, \"type\": t}\n",
    "        for s, e, txt, t in zip(\n",
    "            entities_dict[\"start\"],\n",
    "            entities_dict[\"end\"],\n",
    "            entities_dict[\"text\"],\n",
    "            entities_dict[\"type\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "# Apply to every split inalready-split dict: per_source_raw (1177/lt/wiki)\n",
    "per_source_norm = {}\n",
    "for cfg, ds in per_source_raw.items():\n",
    "    per_source_norm[cfg] = ds.map(\n",
    "        lambda ex: {\n",
    "            **ex,\n",
    "            \"entities\": dict_of_lists_to_list_of_dicts(ex[\"entities\"])\n",
    "        }\n",
    "    )\n",
    "# We inspect the first few examples \n",
    "#per_source_norm[\"1177\"][\"train\"].select(range(3)).to_pandas()[[\"sid\",\"sentence\",\"entities\"]]\n",
    "#per_source_norm[\"1177\"][\"validation\"].select(range(3)).to_pandas()[[\"sid\",\"sentence\",\"entities\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c5c157a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: 1177\n",
      "  Split: train, first example 'entities': [{'start': 0, 'end': 11, 'text': 'Alvedon', 'type': 1}, {'start': 46, 'end': 56, 'text': 'munnen', 'type': 2}, {'start': 70, 'end': 101, 'text': 'munsönderfallande tabletter', 'type': 1}]\n",
      "  Split: validation, first example 'entities': [{'start': 0, 'end': 10, 'text': 'Demens', 'type': 0}]\n",
      "---\n",
      "Config: lt\n",
      "  Split: train, first example 'entities': [{'start': 11, 'end': 20, 'text': 'syndrom', 'type': 0}]\n",
      "  Split: validation, first example 'entities': [{'start': 41, 'end': 52, 'text': 'läkemedel', 'type': 1}]\n",
      "---\n",
      "Config: wiki\n",
      "  Split: train, first example 'entities': [{'start': 34, 'end': 43, 'text': 'lysosom', 'type': 2}]\n",
      "  Split: validation, first example 'entities': [{'start': 13, 'end': 32, 'text': 'limbiska systemet', 'type': 2}]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# We do a check\n",
    "for cfg, ds in per_source_norm.items():\n",
    "    print(f\"Config: {cfg}\")\n",
    "    for split in ds.keys():\n",
    "        print(f\"  Split: {split}, first example 'entities': {ds[split][0]['entities']}\")\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2836a6",
   "metadata": {},
   "source": [
    "We now have the entities as a list: `list[{\"start\",\"end\",\"text\",\"type\"}]`, and the type as an `int` (ClassLabel id), matching the dataset’s schema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e38a6",
   "metadata": {},
   "source": [
    "### 3) Build global BIO labels (union over configs)\n",
    "We'll keep the BIO tags readable (B-body_structure, etc.) by mapping the int codes to the official names during featurization. No dataset mutation needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "125464e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_list: ['O', 'B-body_structure', 'I-body_structure', 'B-disorder_finding', 'I-disorder_finding', 'B-pharmaceutical_drug', 'I-pharmaceutical_drug']\n",
      "label2id: {'O': 0, 'B-body_structure': 1, 'I-body_structure': 2, 'B-disorder_finding': 3, 'I-disorder_finding': 4, 'B-pharmaceutical_drug': 5, 'I-pharmaceutical_drug': 6}\n",
      "id2label: {0: 'O', 1: 'B-body_structure', 2: 'I-body_structure', 3: 'B-disorder_finding', 4: 'I-disorder_finding', 5: 'B-pharmaceutical_drug', 6: 'I-pharmaceutical_drug'}\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "label_list = build_bio_label_list_from_sources(per_source_raw)\n",
    "label2id = {l: i for i, l in enumerate(label_list)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "print(f\"label_list: {label_list}\")\n",
    "print(f\"label2id: {label2id}\")\n",
    "print(f\"id2label: {id2label}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13af0d",
   "metadata": {},
   "source": [
    "### 4) Normalize entities (shape + types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "850127bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# 3a) Iterator that yields (start, end, type_token) regardless of shape\n",
    "NAME_TO_TOKEN = {\n",
    "    \"Disorder and Finding\": \"disorder_finding\",\n",
    "    \"Pharmaceutical Drug\": \"pharmaceutical_drug\",\n",
    "    \"Body Structure\": \"body_structure\",\n",
    "}\n",
    "\n",
    "def iter_entities(example, type_names):\n",
    "    \"\"\"Yield entity spans and their type tokens from an example.\"\"\"\n",
    "    entities = example.get(\"entities\", None)  # Get entities from the example\n",
    "\n",
    "    for d in entities:\n",
    "        t = d.get(\"type\")\n",
    "        name = type_names[t] if isinstance(t, int) else str(t)\n",
    "        yield (d.get(\"start\"), d.get(\"end\"), NAME_TO_TOKEN.get(name, name.lower().replace(\" \", \"_\")))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e69b79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITESPACE_OR_BRACKETS = set(\" \\n\\t()[]{}\")\n",
    "\n",
    "def trim_spans(sentence, start, end):\n",
    "    while start < end and sentence[start] in WHITESPACE_OR_BRACKETS:\n",
    "        start += 1\n",
    "    while start < end and sentence[end-1] in WHITESPACE_OR_BRACKETS:\n",
    "        end -= 1\n",
    "    return (start, end)\n",
    "\n",
    "def make_to_features_offset(tokenizer, label2id, type_names, max_length=256):\n",
    "    \"\"\"Create a function to convert examples to features with offset mapping.\"\"\"\n",
    "    NAME_TO_TOKEN = {\n",
    "        \"Disorder and Finding\": \"disorder_finding\",\n",
    "        \"Pharmaceutical Drug\": \"pharmaceutical_drug\",\n",
    "        \"Body Structure\": \"body_structure\",\n",
    "    }\n",
    "\n",
    "    def type_token(t):\n",
    "        \"\"\"Map entity type to token.\"\"\"\n",
    "        name = type_names[t] if isinstance(t, int) else str(t)\n",
    "        return NAME_TO_TOKEN.get(name, name.lower().replace(\" \", \"_\"))\n",
    "\n",
    "    def to_features(ex, TRIM_SPANS=True):\n",
    "        \"\"\"Convert a single example to features.\"\"\"\n",
    "        text = ex[\"sentence\"]\n",
    "        entities = ex.get(\"entities\", []) or []\n",
    "\n",
    "        enc = tokenizer(text, truncation=True, max_length=max_length, return_offsets_mapping=True)\n",
    "        offsets = enc[\"offset_mapping\"]\n",
    "\n",
    "        # --- ONLY LOCAL COPIES: build trimmed spans for labeling ---\n",
    "        ent_spans = []\n",
    "        for e in entities:\n",
    "            est, eend = e[\"start\"], e[\"end\"]\n",
    "            if TRIM_SPANS:\n",
    "                est, eend = trim_spans(text, est, eend)   # trim away brackets\n",
    "            if est >= eend:\n",
    "                continue              \n",
    "            etok = type_token(e[\"type\"])\n",
    "            ent_spans.append((est, eend, etok))\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        labels = []\n",
    "        for (ts, te) in offsets:\n",
    "            if ts == te:         \n",
    "                labels.append(-100)\n",
    "                continue\n",
    "            lab = \"O\"\n",
    "            for (est, eend, etok) in ent_spans:\n",
    "                if not (te <= est or ts >= eend):    # overlap\n",
    "                    lab = f\"B-{etok}\" if ts <= est < te else f\"I-{etok}\"\n",
    "                    break\n",
    "            labels.append(label2id.get(lab, label2id[\"O\"]))\n",
    "\n",
    "        enc.pop(\"offset_mapping\")\n",
    "        enc[\"labels\"] = labels\n",
    "        return enc\n",
    "\n",
    "    return to_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e58afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3b) Minimal offset-based featurizer (no whitespace pre-tokens)\n",
    "# def make_to_features_offset(tokenizer, label2id, type_names, max_length=256):\n",
    "#     def to_features(ex):\n",
    "#         text = ex[\"sentence\"]\n",
    "#         enc = tokenizer(text, truncation=True, max_length=max_length, return_offsets_mapping=True)\n",
    "#         offsets = enc[\"offset_mapping\"]\n",
    "\n",
    "#         # collect entity spans once\n",
    "#         ent_spans = list(iter_entities(ex, type_names))  # [(start, end, 'pharmaceutical_drug'), ...]\n",
    "\n",
    "#         labels = []\n",
    "#         for (ts, te) in offsets:\n",
    "#             if ts == te:          # special tokens\n",
    "#                 labels.append(-100)\n",
    "#                 continue\n",
    "#             lab = \"O\"\n",
    "#             for (est, eend, etok) in ent_spans:\n",
    "#                 if not (te <= est or ts >= eend):   # overlap\n",
    "#                     lab = f\"B-{etok}\" if ts <= est < te else f\"I-{etok}\"\n",
    "#                     break\n",
    "#             labels.append(label2id.get(lab, label2id[\"O\"]))\n",
    "\n",
    "#         enc.pop(\"offset_mapping\")\n",
    "#         enc[\"labels\"] = labels\n",
    "#         return enc\n",
    "#     return to_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a5cadfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1177] validation featurization: 100%|██████████| 47/47 [00:00<00:00, 2129.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KB/bert-base-swedish-cased\", use_fast=True)\n",
    "\n",
    "# Read names from RAW split (has the ClassLabel feature)\n",
    "type_names = per_source_raw[\"1177\"][\"validation\"].features[\"entities\"].feature[\"type\"].names # Ad hoc fix\n",
    "\n",
    "split = per_source_norm[\"1177\"][\"validation\"]   # <- normalized\n",
    "# ['Disorder and Finding', 'Pharmaceutical Drug', 'Body Structure']\n",
    "\n",
    "to_features = make_to_features_offset(tokenizer, label2id, type_names, max_length=256)\n",
    "\n",
    "ds_1177_val_feats = split.map(\n",
    "    to_features,\n",
    "    batched=False,\n",
    "    remove_columns=split.column_names,\n",
    "    desc=\"[1177] validation featurization\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab0e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1177_650</td>\n",
       "      <td>( Demens ) innebär att man på olika sätt får svårt att minnas och att tolka sin omgivning.</td>\n",
       "      <td>[{'start': 0, 'end': 10, 'text': 'Demens', 'type': 0}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1177_408</td>\n",
       "      <td>Rökare har stor risk att utveckla sjukdomen ( kol ) , ( kronisk obstruktiv lungsjukdom ) .</td>\n",
       "      <td>[{'start': 44, 'end': 51, 'text': 'kol', 'type': 0}, {'start': 54, 'end': 88, 'text': 'kronisk obstruktiv lungsjukdom', 'type': 0}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sid  \\\n",
       "0  1177_650   \n",
       "1  1177_408   \n",
       "\n",
       "                                                                                     sentence  \\\n",
       "0  ( Demens ) innebär att man på olika sätt får svårt att minnas och att tolka sin omgivning.   \n",
       "1  Rökare har stor risk att utveckla sjukdomen ( kol ) , ( kronisk obstruktiv lungsjukdom ) .   \n",
       "\n",
       "                                                                                                                              entities  \n",
       "0                                                                               [{'start': 0, 'end': 10, 'text': 'Demens', 'type': 0}]  \n",
       "1  [{'start': 44, 'end': 51, 'text': 'kol', 'type': 0}, {'start': 54, 'end': 88, 'text': 'kronisk obstruktiv lungsjukdom', 'type': 0}]  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split.select(range(2)).to_pandas()[[\"sid\", \"sentence\", \"entities\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "adb16cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nysningar och ( nästäppa ) kan ofta dämpas av [ nässprej ] , kliande och ( svullna ögon ) går att behandla med [ ögondroppar ] .\n",
      "entities: [(14, 26, 'disorder_finding'), (46, 58, 'pharmaceutical_drug'), (73, 89, 'disorder_finding'), (111, 126, 'pharmaceutical_drug')]\n",
      "Ny              (0, 2)  O\n",
      "##sn            (2, 4)  O\n",
      "##ingar         (4, 9)  O\n",
      "och             (10, 13)  O\n",
      "(               (14, 15)  O\n",
      "näst            (16, 20)  B-disorder_finding\n",
      "##äpp           (20, 23)  I-disorder_finding\n",
      "##a             (23, 24)  I-disorder_finding\n",
      ")               (25, 26)  O\n",
      "kan             (27, 30)  O\n",
      "ofta            (31, 35)  O\n",
      "dämpa           (36, 41)  O\n",
      "##s             (41, 42)  O\n",
      "av              (43, 45)  O\n",
      "[               (46, 47)  O\n",
      "näs             (48, 51)  B-pharmaceutical_drug\n",
      "##spre          (51, 55)  I-pharmaceutical_drug\n",
      "##j             (55, 56)  I-pharmaceutical_drug\n",
      "]               (57, 58)  O\n",
      ",               (59, 60)  O\n",
      "kli             (61, 64)  O\n",
      "##ande          (64, 68)  O\n",
      "och             (69, 72)  O\n",
      "(               (73, 74)  O\n",
      "svull           (75, 80)  B-disorder_finding\n",
      "##na            (80, 82)  I-disorder_finding\n",
      "ögon            (83, 87)  I-disorder_finding\n",
      ")               (88, 89)  O\n",
      "går             (90, 93)  O\n",
      "att             (94, 97)  O\n",
      "behandla        (98, 106)  O\n",
      "med             (107, 110)  O\n",
      "[               (111, 112)  O\n",
      "ögon            (113, 117)  B-pharmaceutical_drug\n",
      "##dr            (117, 119)  I-pharmaceutical_drug\n",
      "##oppar         (119, 124)  I-pharmaceutical_drug\n",
      "]               (125, 126)  O\n",
      ".               (127, 128)  O\n"
     ]
    }
   ],
   "source": [
    "ex0 = per_source_norm[\"1177\"][\"validation\"][2]\n",
    "print(ex0[\"sentence\"])\n",
    "print(\"entities:\", list(iter_entities(ex0, type_names)))\n",
    "\n",
    "enc0 = tokenizer(ex0[\"sentence\"], return_offsets_mapping=True, truncation=True, max_length=256)\n",
    "labs0 = make_to_features_offset(tokenizer, label2id, type_names)(ex0)[\"labels\"]\n",
    "tokens = tokenizer.convert_ids_to_tokens(enc0[\"input_ids\"])\n",
    "\n",
    "for tok, off, lab_id in zip(tokens, enc0[\"offset_mapping\"], labs0):\n",
    "    if lab_id == -100: \n",
    "        continue\n",
    "    print(f\"{tok:15} {off}  {id2label[lab_id]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995c9b6",
   "metadata": {},
   "source": [
    "Note that brackets `()`, `[]`, `{}` are now labeled as O. However, the start and end positions are the same as before pointing to the brackets. The BIO labels align with real entity content only, not the brackets. More importantly, the text has been further tokenized, using AutoTokenizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
